# 分布式SQL数据库
## 关系型数据库现状
随着时代的发展，各种终端的普及，应用和数据的规模越来越大，各种云服务的方案层出不穷。 在这个一切都可以水平扩展的时代，机器可扩展，服务可扩展，监控可扩展，缓存可扩展..... 然而，作为大多数应用最底层的数据存储 -- 关系型数据库， 难以找到一个优雅易用的水平扩展解决方案，一直以来不得不依赖主从复制，静态 Sharding 以及各种业务层的 Workarounds 勉强应对。

## NOSQL的兴起和优缺点
现代计算系统每天在网络上都会产生庞大的数据量。这些数据有很大一部分是由关系型数据库管理系统（RDBMSs）来处理，其严谨成熟的数学理论基础使得数据建模和应用程序编程更加简单。但随着信息化的浪潮和互联网的兴起，传统的RDBMS在一些业务上开始出现问题。首先，对数据库存储的容量要求越来越高，单机无法满足需求，很多时候需要用集群来解决问题，而RDBMS由于要支持join，union等操作，一般不支持分布式集群。其次，在大数据大行其道的今天，很多的数据都“频繁读和增加，不频繁修改”，而RDBMS对所有操作一视同仁，这就带来了优化的空间。另外，互联网时代业务的不确定性导致数据库的存储模式也需要频繁变更，不自由的存储模式增大了运维的复杂性和扩展的难度。
### 优点
易扩展
NoSQL数据库种类繁多，但是有一个共同的特点，都是去掉了关系型数据库的关系型特性。数据之间无关系，这样就非常容易扩展。也无形之间，在架构的层面上带来了可扩展的能力。
大数据量，高性能
NoSQL数据库都具有非常高的读写性能，尤其在大数据量下，同样表现优秀。这得益于它的无关系性，数据库的结构简单。一般MySQL使用Query Cache，每次表更新Cache就失效，是一种大粒度的Cache，针对web2.0的交互频繁的应用，Cache性能不高。而NoSQL的Cache是记录级的，是一种细粒度的Cache，所以NoSQL在这个层面上来说性能就要高很多了。
灵活的数据模型
NoSQL无需事先为要存储的数据建立字段，随时可以存储自定义的数据格式。而在关系型数据库里，增删字段是一件非常麻烦的事情。如果是非常大数据量的表，增加字段简直就是一个噩梦。这点在大数据量的web2.0时代尤其明显。
高可用
NoSQL在不太影响性能的情况下，就可以方便地实现高可用的架构。比如Cassandra、HBase模型，通过复制模型也能实现高可用。
### 缺点
没有标准
没有对NoSQL数据库定义的标准，所以没有两个NoSQL数据库是平等的。
没有存储过程
NoSQL数据库中大多没有存储过程。
不支持SQL
NoSQL大多不提供对SQL的支持：如果不支持SQL这样的工业标准，将会对用户产生一定的学习和应用迁移上的成本。
支持的特性不够丰富，产品不够成熟
现有产品所提供的功能都比较有限，不像MS SQL Server和Oracle那样能提供各种附加功能，比如BI和报表等。大多数产品都还处于初创期，和关系型数据库几十年的完善不可同日而语。

### NoSQL与SQL的对比

|  | RDBMS | NoSQL |
| --- | --- | --- |
| 模式 | 预定义的模式 | 没有预定义的模式 |
| 查询语言 | 结构化查询语言（SQL） | 没有声明性查询语言 |
| 一致性 | 严格的一致性 | 最终一致性 |
| 事务 | 支持 | 不支持 |
| 理论基础 | ACID | CAP, BASE |
| 扩展 | 纵向扩展 | 横向扩展(分布式) |

## NoSQL数据库的分类

### 键值(Key-Value)存储数据库
这一类数据库主要会使用到哈希表，在这个表中有一个特定的键和一个指针指向特定的数据。Key/value模型对于IT系统来说优势在于简单、易部署。但是如果DBA只对部分值进行查询或更新的时候，Key/value就显得效率低下了。
E. g:
TokyoCabinet/Tyrant
Redis
Voldemort
OracleBDB
### 列存储数据库
这部分数据库通常是用来应对分布式存储的海量数据。键仍然存在，但是它们的特点是指向了多个列。这些列是由列家族来安排的。
E. g:
Cassandra
HBase
Riak
### 文档型数据库
文档型数据库的灵感来自于Lotus Notes办公软件，它同第一种键值存储相类似。该类型的数据模型是版本化的文档，半结构化的文档以特定的格式存储，比如JSON。文档型数据库可以看作是键值数据库的升级版，允许之间嵌套键值。而且文档型数据库比键值数据库的查询效率更高。
E. g:
CouchDB
MongoDB
SequoiaDB
### 图形(Graph)数据库
图形结构的数据库同其它行列以及刚性结构的SQL数据库不同，它是使用灵活的图形模型，并且能够扩展到多个服务器上。NoSQL数据库没有标准的查询语言(SQL)，因此进行数据库查询需要制定数据模型。许多NoSQL数据库都有REST式的数据接口或者查询API。
E. g:
Neo4J
InfoGrid
InfiniteGraph

## 新一代分布式SQL数据库的必备特点

* 无缝的水平扩展，应用层可以不用关心存储的容量和吞吐。
* SQL 支持，SQL 有着良好的易用性和生态系统。业务层如果已经在使用 SQL ，转变到 NoSQL 上是个极其痛苦的过程。
* 完整的 ACID 事务支持，应用层不需要关心跨行事务的实现，不需要写很多 hack 代码来确保数据的安全性。
* 更强的 MVCC，可以无锁的访问任意时间点的数据库快照。
* 在线的 Schema 变更，不需要每次更新Schema都要面临停止服务的窘境。
* 零迁移成本，兼容现有的协议或者查询语法，已有的代码不需要做改动或很少改动自动就能获得扩展的能力。

## TiDB
TiDB开源的分布式数据库，参考 Google F1/Spanner 实现了水平伸缩，一致性的分布式事务，多副本同步复制等重要 NewSQL 特性。结合了 RDBMS 和 NoSQL 的优点，部署简单，在线扩容和表结构变更不影响业务，异地多活保障数据安全，同时完全兼容 MySQL / PostgreSQL 协议，使迁移使用成本降到极低。

[关于 TiDB 的正确使用姿势](https://zhuanlan.zhihu.com/p/25574778)
[Apache HAWQ与TiDB比较](https://www.zhihu.com/question/54597742)
## CockroachDB
CockroachDB是一个基于事务和强一致性键值存储构建的分布式SQL数据库。 它支持水平缩放; 可以容忍磁盘
、机器、机架，甚至数据中心故障，并能在极短时间内无需人工干预的恢复服务; 支持强一致的ACID事务; 并提供了类SQL API来构造、操作和查询数据。

蟑螂是一个分布式的K/V数据仓库，支持ACID事务，多版本值存储是其首要特性。主要的设计目标是全球一致性和可靠性，从蟑螂的命名上是就能看出这点。蟑螂数据库能处理磁盘、物理机器、机架甚至数据中心失效情况下最小延迟的服务中断；整个失效过程无需人工干预。蟑螂的节点是均衡的，其设计目标是同质部署（只有一个二进制包）且最小配置。

蟑螂数据库实现了单一的、巨大的有序映射，键和值都是字节串形式（不是unicode），支持线性扩展，理论上支持4EB的逻辑数据）。映射有一个或者多个Range组成，每一个Range对应一个把数据存储在RocksDB（LevelDB的一个变种，Facebook贡献）上的K/V数据库，并且复制到三个或者更多蟑螂服务器上，Range定义为有开始和结束键值的区间。Range可以合并及分裂来维持总大小在一个全局配置的最大最小范围之间。Range的大小默认是64M，目的是便于快速分裂和合并，在一个热点键值区间快速分配负载。Range的复制确定为分离的数据中心来达到可靠性（比如如下分组：{ US-East, US-West, Japan }, { Ireland, US-East, US-West}, { Ireland, US-East, US-West, Japan, Australia }）

 Range有一种变化，通过分布式一致性算法实例来调节确保一致性，蟑螂所选择使用Raft一致性算法。所有的一致性状态存在于RocksDB中。
 
  一个逻辑上的变化可能会影响多个K/V对，逻辑变化是ACID事务性的。如果一个逻辑的变化引起的所有的键值都落在同一个Range里，Raft保证事务的原子性和一致性；不然的话，一个无锁的分布式提交协议用来协同受影响的Range。

 蟑螂提供快照隔离级别和可串行化快照隔离级别，允许外部一致性和无锁读写，这些都依赖于快照时间戳和当前时间。快照一致性提供无锁读写，但是依然允许写偏。SSI（可串行化快照隔离级别）消除写偏，但是引入了一个有争议系统的性能损失。SSI是默认的隔离级别；为了性能客户端必须自己处理交易的正确性。蟑螂实现了和Spannerde 目录相似，蟑螂允许任意数据zone的配置。允许选择复制因子、存储设备类型及数据中心位置等配置来优化性能或者可用性。不像Spaner，zone是一个整体，不允许对实体组水平的细粒度数据进行移动。
 
 提供一个类Megastore的消息队列机制来：可以容许异步执行的高效地sideline更新，以及，提供一个集成消息队列系统来用于分布式系统的组件之间的异步通信。
 
 [cockroachdb设计翻译](https://lihuanghe.github.io/2016/05/06/cockroachdb-design.html)
 
## BDRT
天云大数据BDRT（Beagledata Realtime Transaction）是一款大规模高并发支持灵活查询的实时查询引擎，具有高可用、可横向扩展、健壮性的特点，支持数据自动均匀分布、支持索引及事务控制、支持REST、SQL、SDK等接口，支持上千个用户并发的进行实时查询。

BDRT是在总结了多年大型银行大数据项目实施经验的基础上，针对海量数据实时模糊搜索查询场景抽象出的最佳实践工具。BDRT具有海量数据高效插入、读取和快速响应以及丰富的条件检索等特点，同时融入关系型数据库中事务的概念，形成的一套完整的支持分布式数据一致性的实时模糊搜索服务解决方案。

BDRT具有包括Java、Python、Scala SDK，RESTFul API，SQL等多种读写接口，可同时满足FTP、MQ、Sqoop、Flume、Kafka等多种数据接入方式，同时支持天云自有交换平台的数据接入。同时利用多种多样的接口可向各类业务应用推送需要的数据。支持全量导入、增量导入数据、读取数据支持分页等细节功能。
保持数据事务一致性,对ACID的有效支撑。事务控制层可以支持安全的使用并发的多线程。可以支持对一个数据对象或方法在读写上的提交与回滚。在事务完成时，无论成功或者回滚，数据在多个节点都会处于一致的状态。
为了更好的查询效率和对各种数据类型有更好的支持，BDRT索引包含了多种数据类型的索引，这些数据类型包括：Byte、Short、Integer、Long、Float、Double、Decimal、Precision、String、Date、Instant等，有了这些数据类型，索引就可以根据业务实际需要来进行选择，紧密的和业务结合在一起。
通过持久化接口将数据在BDRT中持久化。BDRT原生支持了多种数据类型，这些类型包括：String、Character、Boolean、Byte、Short、Integer、Long、Float、Double、Decimal（拥有三位小数的数字）、Precision（拥有6位小数的数字）、Date、UUID。

### BDRT查询引擎具有下列特性：
* 与hadoop生态圈紧密结合，可与其他hadoop组件进行无缝集成。
* 支持数据和用户的高扩展，水平扩展非常容易。支持高效稳定的海量数据存储，可有效支持上亿行、上百万列、上万个版本，支持对数据自动分片。
* 具有容错性的数据分发和备份，对索引分片，并对每个分片创建多个副本。每个副本都可以对外提供服务。一个副本的异常不会对整个集群提供索引服务造成影响。
* 支持高可用性和热备份。
* 支持对数据进行各种高级查询，包括交集、联集、排除、通配符、范围、分页、排序、Group等。
* 读写严格一致，支持ACID（ACID指数据库正确执行的四个基本要素，包括:原子性，一致性，隔离性，持久性）和最终一致性。支持事务的提交和回滚，有效保障了数据的完整性。
* 数据查询的秒级毫秒级响应，从而支持OLTP。

### 产品优势：
* 采用分布式架构解决数据的安全性、稳定性，相对于传统关系型数据库，大大提高了数据的存储容量。
* 支持数据和用户的高扩展，水平扩展非常容易。支持高效稳定的海量数据存储，可有效支持上亿行、上百万列、上万个版本，支持对数据自动分片。
* 具有容错性的数据分发和备份，对索引分片，并对每个分片创建多个副本。每个副本都可以对外提供服务。一个副本的异常不会对整个集群提供索引服务造成影响。
* 支持对数据进行各种高级查询，包括交集、联集、排除、通配符、范围、分页、排序、Group等。
* 读写严格一致，支持ACID。支持事务的提交和回滚，有效保障了数据的完整性。
* 数据查询的秒级毫秒级响应，从而支持OLTP。
* 可与其他组件可以做到轻松集成，既可以与业务系统结合，将读数据放到BDRT端，来做读写分离，为业务系统减负，也可通过大数据平台hadoop和spark进行ETL处理，从而支持OLAP。
* 良好的开发规范和完善的文档支持，降低了开发人员的使用门槛，无需关心BDRT的底层。

### 适用场景：
* 利用BDRT低延时、高性能、海量存储等特性，满足需要从海量的历史和实时数据中秒级获取有效信息的场景。
* 在分布式背景下，数据量不断的增长，需要高速的读写，并有复杂的ETL需要的场景。
* 用户使用频率非常高，重要程度仅次于核心应用，对数据的丢失以及服务的中断零容忍的场景。
* 对数据的一致性有要求的场景。

## 基础技术原理和名称术语

### CAP
CAP原则又称CAP定理，指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。

分布式系统的CAP理论：理论首先把分布式系统中的三个特性进行了如下归纳：
* 一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）
* 可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）
* 分区容错性（P）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。

2000年，Eric Brewer提出了一个猜想：

* C（一致性）：所有的节点上的数据时刻保持同步
* A（可用性）：每个请求都能接受到一个响应，无论响应成功或失败
* P（分区容错）：系统应该能持续提供服务，即使系统内部有消息丢失（分区）
高可用、数据一致是很多系统设计的目标，但是分区又是不可避免的事情：
* CA without P：如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但其实分区不是你想不想的问题，而是始终会存在，因此CA的系统更多的是允许分区后各子系统依然保持CA。
* CP without A：如果不要求A（可用），相当于每个请求都需要在Server之间强一致，而P（分区）会导致同步时间无限延长，如此CP也是可以保证的。很多传统的数据库分布式事务都属于这种模式。
* AP wihtout C：要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。现在众多的NoSQL都属于此类。

2002年，Lynch与其他人证明了Brewer猜想，CAP的定义进行了更明确的声明:

* C：一致性被称为原子对象，任何的读写都应该看起来是“原子“的，或串行的。**写后面的读一定能读到前面写的内容**。所有的读写请求都好像被全局排序。
* A：对任何非失败节点都应该在有限时间内给出请求的回应。（请求的可终止性）。
* P：允许节点之间丢失任意多的消息，当网络分区发生时，节点之间的消息可能会完全丢失。

Brewer和Lynch于2012年补充完善了CAP理论：
* 把CAP理论的证明局限在原子读写的场景，并申明不支持数据库事务之类的场景
* 一致性场景不会引入用户agent，只是发生在后台集群之内
* 把分区容错归结为一个对网络环境的陈述，而非之前一个独立条件。这实际上就是更加明确了概念
* 引入了活性(liveness)和安全属性(safety)，在一个更抽象的概念下研究分布式系统，并认为CAP是活性与安全属性之间权衡的一个特例。其中的一致性属于liveness，可用性属于safety
* 把CAP的研究推到一个更广阔的空间：网络存在同步、部分同步；一致性性的结果也从仅存在一个到存在N个（部分一致）；引入了通信周期round，并引用了其他论文，给出了为了保证N个一致性结果，至少需要通信的round数。

CAP并不适合再作为一个适应任何场景的定理，它的正确性更加适合基于原子读写的NoSQL场景。

### ACID
传统的SQL数据库的事务通常都是支持ACID的强事务机制。
#### 原子性
一个事务包含多个操作，这些操作要么全部执行，要么全都不执行。实现事务的原子性，要支持回滚操作，在某个操作失败后，回滚到事务执行之前的状态。
     回滚实际上是一个比较高层抽象的概念，大多数DB在实现事务时，是在事务操作的数据快照上进行的（比如MVCC），并不修改实际的数据，如果有错并不会提交，所以很自然的支持回滚。
     而在其他支持简单事务的系统中，不会在快照上更新，而直接操作实际数据。可以先预演一边所有要执行的操作，如果失败则这些操作不会被执行，通过这种方式很简单的实现了原子性。
#### 一致性（Consistency）
一致性是指事务使得系统从一个一致的状态转换到另一个一致状态。在事务开始和完成时，数据必须保持一致状态，相关的数据规则必须应用于事务的修改，以保证数据的完整性，事务结束时，所有的内部数据结构必须正确
事务的一致性决定了一个系统设计和实现的复杂度。事务可以不同程度的一致性：
     **强一致性：**读操作可以立即读到提交的更新操作。
     **弱一致性：**提交的更新操作，不一定立即会被读操作读到，此种情况会存在一个不一致窗口，指的是读操作可以读到最新值的一段时间。
     **最终一致性：**是弱一致性的特例。事务更新一份数据，最终一致性保证在没有其他事务更新同样的值的话，最终所有的事务都会读到之前事务更新的最新值。如果没有错误发生，不一致窗口的大小依赖于：通信延迟，系统负载等。
     其他一致性变体还有：
     **单调一致性：**如果一个进程已经读到一个值，那么后续不会读到更早的值。
     **会话一致性：**保证客户端和服务器交互的会话过程中，读操作可以读到更新操作后的最新值。
#### 隔离性（Isolation）
并发事务之间互相影响的程度，比如一个事务会不会读取到另一个未提交的事务修改的数据。
在事务并发操作时，可能出现的问题有：
     **脏读：**事务A修改了一个数据，但未提交，事务B读到了事务A未提交的更新结果，如果事务A提交失败，事务B读到的就是脏数据。
     **不可重复读：**在同一个事务中，对于同一份数据读取到的结果不一致。比如，事务B在事务A提交前读到的结果，和提交后读到的结果可能不同。不可重复读出现的原因就是事务并发修改记录，要避免这种情况，最简单的方法就是对要修改的记录加锁，这回导致锁竞争加剧，影响性能。另一种方法是通过MVCC可以在无锁的情况下，避免不可重复读。
     **幻读：**在同一个事务中，同一个查询多次返回的结果不一致。事务A新增了一条记录，事务B在事务A提交前后各执行了一次查询操作，发现后一次比前一次多了一条记录。幻读是由于并发事务增加记录导致的，这个不能像不可重复读通过记录加锁解决，因为对于新增的记录根本无法加锁。需要将事务串行化，才能避免幻读。
     事务的隔离级别从低到高有：
     **Read Uncommitted：**最低的隔离级别，什么都不需要做，一个事务可以读到另一个事务未提交的结果。所有的并发事务问题都会发生。
     **Read Committed：**只有在事务提交后，其更新结果才会被其他事务看见。可以解决脏读问题。
     **Repeated Read：**在一个事务中，对于同一份数据的读取结果总是相同的，无论是否有其他事务对这份数据进行操作，以及这个事务是否提交。可以解决脏读、不可重复读。
     **Serialization：**事务串行化执行，隔离级别最高，牺牲了系统的并发性。可以解决并发事务的所有问题。
     通常，在工程实践中，为了性能的考虑会对隔离性进行折中。
#### 持久性（Durability）
事务提交后，对系统的影响是永久的，即使系统出现故障也能够保持。

### 权衡一致性与可用性 - BASE理论
Base = Basically Available + Soft state + Eventuallyconsistent 基本可用性+软状态+最终一致性，由eBay架构师DanPritchett提出。Base是对CAP中一致性A和可用性C权衡的结果，源于提出者自己在大规模分布式系统上实践的总结。核心思想是无法做到强一致性，但每个应用都可以根据自身的特点，采用适当方式达到最终一致性。
#### BA - Basically Available - 基本可用
基本可用。这里是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心功能或者当前最重要功能可用。对于用户来说，他们当前最关注的功能或者最常用的功能的可用性将会获得保证，但是其他功能会被削弱。
#### S – Soft State - 软状态
允许系统数据存在中间状态，但不会影响到系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步时存在延时。
#### E - Eventually Consistent - 最终一致性
要求系统数据副本最终能够一致，而不需要实时保证数据副本一致。最终一致性是弱一致性的一种特殊情况。最终一致性有5个变种：
* 因果一致性
* 读己之所写(因果一致性特例)
* 会话一致性
* 单调读一致性
* 单调写一致性

## 分布式存储算法和技术实现（Atomic）

### Paxos 一致性算法

[如何浅显易懂地解说 Paxos 的算法](https://www.zhihu.com/question/19787937)
[以两军问题为背景来演绎Basic Paxos](http://iunknown.iteye.com/blog/2246484?from=message&isappinstalled=0)

### 分布式协调和配置服务
etcd是一个高可用的键值存储系统，主要用于共享配置和服务发现。它使用Go语言编写，并通过Raft一致性算法处理日志复制以保证强一致性。Raft是一个来自Stanford的新的一致性算法，适用于分布式系统的日志复制，Raft通过选举的方式来实现一致性，在Raft中，任何一个节点都可能成为Leader。etcd 集群的工作原理基于 raft 共识算法 (The Raft Consensus Algorithm)。raft 共识算法的优点在于可以在高效的解决分布式系统中各个节点日志内容一致性问题的同时，也使得集群具备一定的容错能力。即使集群中出现部分节点故障、网络故障等问题，仍可保证其余大多数节点正确的步进。甚至当更多的节点（一般来说超过集群节点总数的一半）出现故障而导致集群不可用时，依然可以保证节点中的数据不会出现错误的结果。
Raft算法可以通过这个[动画](http://thesecretlivesofdata.com/raft/)来学习。

Zookeeper是一个用户维护配置信息、命名、分布式同步以及分组服务的集中式服务框架，它使用Java语言编写，通过Zab协议来保证节点的一致性，zookeeper是基于paxos的简化版zab。因为Zookeeper是一个CP型系统，所以当网络分区问题发生时，系统就不能注册或查找服务。

当提供K/V存储的时候，读取是强一致性的，并且在面对网络分区的时候，为了保持一致性，读取的可用性是可以牺牲的。


## 为什么使用GO语言实现
编程语言的选择很重要。 速度，稳定性，可维护性，底层语言的这些属性都可以影响BDRT的发展速度以及它的工作原理， 并不是所有的语言都是一样的。 Go是一种开源编程语言，主要在Google开发，作为C ++和Java的可行替代品。
* 建立分布式系统的良好环境
* 编译本机性能
* 垃圾收集和类型安全提供稳定性
* 良好的代码可读行

## 性能测试
[Performance since PostgreSQL 7.4 / TPC-DS](http://blog.pgaddict.com/posts/performance-since-postgresql-7-4-to-9-4-tpc-ds)

[对Imapla&Spark2.0.0SQL进行TPC-DS性能测试](http://www.2cto.com/database/201606/517610.html)

[Spark SQL Performance Tests](https://github.com/databricks/spark-sql-perf)

[SQL on Hadoop TPCDS性能测试](http://www.itweet.cn/2016/04/09/SQL-on-Hadoop-tpc-testing/)


